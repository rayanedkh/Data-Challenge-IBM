# HackatonIBM
## PrÃ©sentation des jeux de donnÃ©es ğŸ“Š

Pour ce data challenge, nous avons dâ€™abord disposÃ© de trois jeux de donnÃ©es au format CSV :  
- *cards_data.csv* ğŸƒ, regroupant les informations relatives aux cartes (type, date dâ€™Ã©mission, limites, etc.)  
- *users_data.csv* ğŸ‘¤, contenant les attributs des utilisateurs (Ã¢ge, genre, localisation, statut)  
- *transactions_train.csv* ğŸ’¸, listant les opÃ©rations effectuÃ©es (montant, date, moyen de paiement, marchand)  

Chacun de ces fichiers prÃ©sentait des colonnes complÃ©mentaires ; nous avons donc procÃ©dÃ© Ã  leur fusion (merge) sur les clÃ©s communes (ID carte et ID utilisateur) afin de constituer un seul jeu de donnÃ©es unifiÃ©, prÃªt pour lâ€™analyse et le prÃ©traitement. ğŸš€

## Ã‰tiquetage de la fraude ğŸš©

Les Ã©tiquettes de fraude (fraud/no-fraud) Ã©taient, quant Ã  elles, fournies dans un fichier JSON Ã  part, nommÃ© *train_fraud_labels.json* ğŸ—‚ï¸.  
Ce fichier associe Ã  chaque identifiant de transaction son label de fraude, nous permettant ainsi de superviser lâ€™apprentissage des modÃ¨les de dÃ©tection. ğŸ”
# ğŸ“Š RÃ©sumÃ© des Performances du ModÃ¨le LGBM â€“ DÃ©tection de Fraude

**ğŸ”¢ Nombre d'instances Ã©valuÃ©es** : 21â€¯000  
**ğŸ§  Algorithme utilisÃ©** : LightGBM (LGBMClassifier)  
**ğŸ§® Nombre de caractÃ©ristiques** : 46  
**ğŸ¯ Colonne cible** : `target` (1 = fraude, 0 = non-fraude)

---

## âœ… Scores d'Ã‰valuation

| **MÃ©trique**               | **Holdout** | **Validation CroisÃ©e** |
|----------------------------|-------------|-------------------------|
| **Exactitude (Accuracy)**  | 0.999       | 0.999                   |
| **AUC-ROC**                | 0.996       | 0.985                   |
| **PrÃ©cision**              | 0.767       | 0.687                   |
| **Rappel (Recall)**        | 0.742       | 0.743                   |
| **F1-Score**               | 0.754       | 0.711                   |
| **PrÃ©cision Moyenne (AP)** | 0.786       | 0.749                   |
| **Log Loss**               | 0.003       | 0.004                   |

---

## ğŸ“Œ Matrice de Confusion

| ObservÃ©       | PrÃ©dit 1 | PrÃ©dit 0 | % Correct |
|---------------|----------|----------|-----------|
| 1 (Fraude)    | 23       | 8        | 74.2%     |
| 0 (Non-fraude)| 7        | 20â€¯962   | 100.0%    |

---

## ğŸ§  InterprÃ©tation des RÃ©sultats

- **PrÃ©cision Ã©levÃ©e** : Le modÃ¨le atteint une prÃ©cision de 76.7% pour la classe fraude, ce qui indique une bonne capacitÃ© Ã  identifier les transactions frauduleuses.
- **Rappel solide** : Avec un rappel de 74.2%, le modÃ¨le dÃ©tecte une proportion significative des fraudes rÃ©elles.
- **AUC-ROC Ã©levÃ©** : Un score AUC-ROC de 0.996 en holdout suggÃ¨re une excellente capacitÃ© de discrimination entre les classes.
- **Log Loss faible** : Une perte logarithmique de 0.003 indique que le modÃ¨le est bien calibrÃ© et confiant dans ses prÃ©dictions.

---

## ğŸ› ï¸ Recommandations

- **Analyse des erreurs** : Ã‰tudiez les cas de fausses alertes (faux positifs) et de fraudes non dÃ©tectÃ©es (faux nÃ©gatifs) pour identifier des motifs ou des caractÃ©ristiques communes.
- **Ajustement du seuil de dÃ©cision** : En fonction de la tolÃ©rance au risque, envisagez d'ajuster le seuil de classification pour Ã©quilibrer davantage la prÃ©cision et le rappel.
- **Surveillance continue** : Mettez en place une surveillance continue des performances du modÃ¨le pour dÃ©tecter toute dÃ©rive ou changement dans les donnÃ©es entrantes.


