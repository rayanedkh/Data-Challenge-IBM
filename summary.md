# HackatonIBM
## PrÃ©sentation des jeux de donnÃ©es ğŸ“Š

Pour ce data challenge, nous avons dâ€™abord disposÃ© de trois jeux de donnÃ©es au format CSV :  
- *cards_data.csv* , regroupant les informations relatives aux cartes (type, date dâ€™Ã©mission, limites, etc.)  
- *users_data.csv* , contenant les attributs des utilisateurs (Ã¢ge, genre, localisation, statut)  
- *transactions_train.csv*, listant les opÃ©rations effectuÃ©es (montant, date, moyen de paiement, marchand)  

Chacun de ces fichiers prÃ©sentait des colonnes complÃ©mentaires ; nous avons donc procÃ©dÃ© Ã  leur fusion (merge) sur les clÃ©s communes (ID carte et ID utilisateur) afin de constituer un seul jeu de donnÃ©es unifiÃ©, prÃªt pour lâ€™analyse et le prÃ©traitement. ğŸš€

## Ã‰tiquetage de la fraude ğŸš©

Les Ã©tiquettes de fraude (fraud/no-fraud) Ã©taient, quant Ã  elles, fournies dans un fichier JSON Ã  part, nommÃ© *train_fraud_labels.json* ğŸ—‚ï¸.  
Ce fichier associe Ã  chaque identifiant de transaction son label de fraude, nous permettant ainsi de superviser lâ€™apprentissage des modÃ¨les de dÃ©tection. ğŸ”

# ğŸ“Š ModÃ¨le LGBM 

**ğŸ”¢ Nombre d'instances Ã©valuÃ©es** : 21â€¯000  
**ğŸ§  Algorithme utilisÃ©** : LightGBM (LGBMClassifier)  
**ğŸ§® Nombre de caractÃ©ristiques** : 46  
**ğŸ¯ Colonne cible** : `target` (1 = fraude, 0 = non-fraude)

---

## Feature Engineering ğŸ› ï¸

- Suppression des colonnes inutiles, telles que **cvv** ğŸ”’ (risque de confidentialitÃ©) et autres attributs peu informatifs  
- Application du **One-Hot Encoding** pour les variables catÃ©gorielles, transformant chaque modalitÃ© en une colonne binaire distincte ğŸ·ï¸

---

## âœ… Scores d'Ã‰valuation

| **MÃ©trique**               | **Holdout** | **Validation CroisÃ©e** |
|----------------------------|-------------|-------------------------|
| **Exactitude (Accuracy)**  | 0.999       | 0.999                   |
| **AUC-ROC**                | 0.996       | 0.985                   |
| **PrÃ©cision**              | 0.767       | 0.687                   |
| **Rappel (Recall)**        | 0.742       | 0.743                   |
| **F1-Score**               | 0.754       | 0.711                   |
| **PrÃ©cision Moyenne (AP)** | 0.786       | 0.749                   |
| **Log Loss**               | 0.003       | 0.004                   |

---

## ğŸ“Œ Matrice de Confusion

| ObservÃ©       | PrÃ©dit 1 | PrÃ©dit 0 | % Correct |
|---------------|----------|----------|-----------|
| 1 (Fraude)    | 23       | 8        | 74.2%     |
| 0 (Non-fraude)| 7        | 20â€¯962   | 100.0%    |

---

## ğŸ§  InterprÃ©tation des RÃ©sultats

- **PrÃ©cision Ã©levÃ©e** : Le modÃ¨le atteint une prÃ©cision de 76.7% pour la classe fraude, ce qui indique une bonne capacitÃ© Ã  identifier les transactions frauduleuses.
- **Rappel solide** : Avec un rappel de 74.2%, le modÃ¨le dÃ©tecte une proportion significative des fraudes rÃ©elles.
- **AUC-ROC Ã©levÃ©** : Un score AUC-ROC de 0.996 en holdout suggÃ¨re une excellente capacitÃ© de discrimination entre les classes.
- **Log Loss faible** : Une perte logarithmique de 0.003 indique que le modÃ¨le est bien calibrÃ© et confiant dans ses prÃ©dictions.

---

## ğŸ› ï¸ Recommandations

- **Analyse des erreurs** : Ã‰tudiez les cas de fausses alertes (faux positifs) et de fraudes non dÃ©tectÃ©es (faux nÃ©gatifs) pour identifier des motifs ou des caractÃ©ristiques communes.
- **Ajustement du seuil de dÃ©cision** : En fonction de la tolÃ©rance au risque, envisagez d'ajuster le seuil de classification pour Ã©quilibrer davantage la prÃ©cision et le rappel.
- **Surveillance continue** : Mettez en place une surveillance continue des performances du modÃ¨le pour dÃ©tecter toute dÃ©rive ou changement dans les donnÃ©es entrantes.

Cette premiere pipeline permet d'avoir les meilleurs compromis entre la prÃ©cision et le rappel, cependant Ã©tant donnÃ© le problÃ¨me il peut Ãªtre pertinent de se concentrer sur le rappel.
Voici les performances d'une autre pipeline qui permet d'atteindre un rappel parfait mais une prÃ©cision faible.
(peut-Ãªtre mieux en function de l'usage du modÃ¨le)

# ğŸ“Š Decision Tree Classifier

## ğŸ§ª DÃ©tails de l'ExpÃ©rience

- **Colonne prÃ©dite** : `target`
- **Algorithme** : Arbre de DÃ©cision (Decision Tree Classifier)
- **Nombre de caractÃ©ristiques** : 76
- **Instances Ã©valuÃ©es** : 21 000

---

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

### âœ… MÃ©triques Holdout (sÃ©paration entraÃ®nement/test classique)

| MÃ©trique             | Valeur |
|----------------------|--------|
| Exactitude (Accuracy) | 0.860  |
| AUC (ROC)            | 0.936  |
| PrÃ©cision            | 0.010  |
| Rappel (Recall)      | 1.000  |
| Score F1             | 0.021  |
| PrÃ©cision Moyenne    | 0.011  |
| Log Loss             | 0.307  |

---

### ğŸ” MÃ©triques en Validation CroisÃ©e

| MÃ©trique             | Valeur |
|----------------------|--------|
| Exactitude (Accuracy) | 0.865  |
| AUC (ROC)            | 0.914  |
| PrÃ©cision            | 0.011  |
| Rappel (Recall)      | 0.954  |
| Score F1             | 0.021  |
| PrÃ©cision Moyenne    | 0.011  |
| Log Loss             | 0.299  |

---

## ğŸ“‰ RÃ©sumÃ© de la Matrice de Confusion (Holdout)

| RÃ©el \ PrÃ©dit        | 1 (Fraude) | 0 (Non-fraude) | % Correct |
|----------------------|------------|----------------|-----------|
| 1 (Fraude)           | 31         | 0              | 100.0%    |
| 0 (Non-fraude)       | 2937       | 18 032         | 86.0%     |

- **Rappel pour la classe 1 (Fraude)** : **100 %**
- **TrÃ¨s faible prÃ©cision (1 %)** : Le modÃ¨le dÃ©tecte tous les cas de fraude, mais avec beaucoup de faux positifs.

---

## ğŸ“ InterprÃ©tation

- Le modÃ¨le Arbre de DÃ©cision **dÃ©tecte toutes les fraudes (rappel = 100 %)**, ce qui est crucial en dÃ©tection de fraude.
- Cependant, sa **prÃ©cision est trÃ¨s faible (1 %)**, ce qui signifie quâ€™il classe Ã  tort de nombreuses transactions normales comme frauduleuses.
- Cela entraÃ®ne un **grand nombre de faux positifs**, pouvant causer des inefficacitÃ©s opÃ©rationnelles ou de la fatigue dâ€™alerte.

ğŸ‘‰ Il est recommandÃ© dâ€™explorer des modÃ¨les plus avancÃ©s (comme LGBM ou Random Forest) ou dâ€™intÃ©grer un apprentissage sensible au coÃ»t pour amÃ©liorer la prÃ©cision.
